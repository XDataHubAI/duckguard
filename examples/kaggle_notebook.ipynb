{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality with DuckGuard - 10x Faster Than Pandas\n",
    "\n",
    "**DuckGuard** is a Python-native data quality tool built on DuckDB.\n",
    "\n",
    "In this notebook, we'll use DuckGuard to:\n",
    "1. Profile the Titanic dataset\n",
    "2. Get instant quality scores\n",
    "3. Detect semantic types and PII\n",
    "4. Create validation rules\n",
    "5. Detect anomalies\n",
    "\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-XDataHubAI%2Fduckguard-blue)](https://github.com/XDataHubAI/duckguard)\n",
    "[![PyPI](https://img.shields.io/pypi/v/duckguard.svg)](https://pypi.org/project/duckguard/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install DuckGuard\n",
    "!pip install duckguard -q\n",
    "print(\"DuckGuard installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckguard import connect, score, detect_anomalies\n",
    "from duckguard.semantic import SemanticAnalyzer\n",
    "from duckguard import load_rules_from_string, execute_rules\n",
    "\n",
    "# Connect to Kaggle dataset (adjust path as needed)\n",
    "# For Titanic competition:\n",
    "# data = connect(\"/kaggle/input/titanic/train.csv\")\n",
    "\n",
    "# For this demo, we'll create sample data\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'PassengerId': range(1, 101),\n",
    "    'Survived': [0, 1] * 50,\n",
    "    'Pclass': [1, 2, 3, 1, 2] * 20,\n",
    "    'Name': [f'Passenger {i}' for i in range(1, 101)],\n",
    "    'Sex': ['male', 'female'] * 50,\n",
    "    'Age': [25, 30, None, 45, 22] * 20,\n",
    "    'Fare': [50.0, 75.5, 10.0, 200.0, 15.5] * 20,\n",
    "    'Embarked': ['S', 'C', 'Q', 'S', None] * 20\n",
    "})\n",
    "df.to_csv('titanic_sample.csv', index=False)\n",
    "\n",
    "data = connect('titanic_sample.csv')\n",
    "print(f\"Loaded {data.row_count} rows, {data.column_count} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instant Quality Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = data.score()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"DATA QUALITY REPORT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nOverall Score: {quality.overall:.1f}/100\")\n",
    "print(f\"Grade: {quality.grade}\")\n",
    "print(f\"\\nDimension Scores:\")\n",
    "print(f\"  Completeness: {quality.completeness:.1f}\")\n",
    "print(f\"  Uniqueness: {quality.uniqueness:.1f}\")\n",
    "print(f\"  Validity: {quality.validity:.1f}\")\n",
    "print(f\"  Consistency: {quality.consistency:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Column Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "for col in data.columns:\n",
    "    null_pct = getattr(data, col).null_percent\n",
    "    if null_pct > 0:\n",
    "        print(f\"  {col}: {null_pct:.1f}% null\")\n",
    "\n",
    "print(f\"\\nFare Statistics:\")\n",
    "print(f\"  Min: {data.Fare.min}\")\n",
    "print(f\"  Max: {data.Fare.max}\")\n",
    "print(f\"  Mean: {data.Fare.mean:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Semantic Type Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckguard import detect_types_for_dataset\n",
    "\n",
    "types = detect_types_for_dataset(data)\n",
    "print(\"Detected Semantic Types:\")\n",
    "for col, sem_type in types.items():\n",
    "    type_name = sem_type.value if sem_type else \"generic\"\n",
    "    print(f\"  {col}: {type_name}\")\n",
    "\n",
    "# Check for PII\n",
    "analyzer = SemanticAnalyzer()\n",
    "analysis = analyzer.analyze(data)\n",
    "if analysis.pii_columns:\n",
    "    print(f\"\\n⚠️ Potential PII in: {analysis.pii_columns}\")\n",
    "else:\n",
    "    print(\"\\n✓ No obvious PII detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. YAML Validation Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_yaml = \"\"\"\n",
    "dataset: titanic\n",
    "rules:\n",
    "  - PassengerId is not null\n",
    "  - PassengerId is unique\n",
    "  - Survived in [0, 1]\n",
    "  - Pclass in [1, 2, 3]\n",
    "  - Age >= 0\n",
    "  - Fare >= 0\n",
    "  - Sex in ['male', 'female']\n",
    "\"\"\"\n",
    "\n",
    "rules = load_rules_from_string(rules_yaml)\n",
    "result = execute_rules(rules, dataset=data)\n",
    "\n",
    "print(f\"Results: {result.passed_count}/{result.total_checks} passed\")\n",
    "print(f\"Quality Score: {result.quality_score:.1f}%\")\n",
    "print(\"\\nDetails:\")\n",
    "for r in result.results:\n",
    "    status = \"✓ PASS\" if r.passed else \"✗ FAIL\"\n",
    "    print(f\"  [{status}] {r.check.expression}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = detect_anomalies(data, method=\"iqr\", threshold=1.5)\n",
    "\n",
    "print(f\"Anomaly Detection (IQR method):\")\n",
    "print(f\"Columns checked: {report.statistics.get('columns_checked', 0)}\")\n",
    "print(f\"Anomalies found: {report.anomaly_count}\")\n",
    "\n",
    "for a in report.anomalies:\n",
    "    status = \"⚠️ ANOMALY\" if a.is_anomaly else \"✓ OK\"\n",
    "    print(f\"  {status} {a.column}: {a.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Auto-Generate Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckguard import generate_rules\n",
    "\n",
    "# Auto-generate rules from data\n",
    "generated = generate_rules(data, dataset_name=\"titanic\")\n",
    "print(\"Auto-Generated Rules:\")\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "DuckGuard provides:\n",
    "- **Instant quality scores** with A-F grades\n",
    "- **Semantic type detection** including PII\n",
    "- **YAML-based validation rules**\n",
    "- **Anomaly detection** with multiple methods\n",
    "- **10x faster** than pandas-based tools\n",
    "\n",
    "### Install & Learn More\n",
    "```bash\n",
    "pip install duckguard\n",
    "```\n",
    "\n",
    "- GitHub: https://github.com/XDataHubAI/duckguard\n",
    "- PyPI: https://pypi.org/project/duckguard/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
