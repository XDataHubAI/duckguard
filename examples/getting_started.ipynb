{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# DuckGuard 2.0 - Getting Started Guide\n\n**DuckGuard** is a Python-native data quality tool built on DuckDB for speed.\n\n## What's New in v2.0\n- **YAML-based Rules**: Define rules in YAML with a simple, clean syntax\n- **Semantic Type Detection**: Auto-detect emails, phones, PII, and 30+ types\n- **Data Contracts**: Schema + quality SLAs with breaking change detection\n- **Anomaly Detection**: Statistical anomaly detection (Z-score, IQR, percent change)\n- **Enhanced CLI**: Beautiful Rich output with new commands\n\nThis notebook walks you through:\n1. Connecting to data sources\n2. Exploring your data\n3. Calculating quality scores\n4. **NEW**: YAML-based rules\n5. **NEW**: Semantic type detection\n6. **NEW**: Data contracts\n7. **NEW**: Anomaly detection\n8. Using with pytest\n9. CLI commands"
  },
  {
   "cell_type": "code",
   "id": "cell-1",
   "metadata": {},
   "source": "# Install DuckGuard from local source (run this first!)\n# This installs the package in editable/development mode with all dependencies\n%pip install -e .. --quiet\n\nprint(\"DuckGuard installed successfully! If you see import errors, restart the kernel.\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# Import DuckGuard - all the new features!\nfrom duckguard import (\n    # Core\n    connect, score, profile,\n    # YAML Rules\n    load_rules, load_rules_from_string, execute_rules, generate_rules, RuleSet,\n    # Semantic Types\n    SemanticType, SemanticAnalyzer, detect_type, detect_types_for_dataset,\n    # Data Contracts\n    DataContract, load_contract, validate_contract, generate_contract, diff_contracts,\n    # Anomaly Detection\n    AnomalyDetector, AnomalyResult, detect_anomalies,\n    # Version\n    __version__\n)\n# Additional contract utilities\nfrom duckguard.contracts import contract_to_yaml\n\nprint(f\"DuckGuard v{__version__} imported successfully!\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": "## 2. Connecting to Data Sources\n\nDuckGuard auto-detects the data source type from the path or connection string."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to a CSV file\n",
    "orders = connect(\"sample_data/orders.csv\")\n",
    "\n",
    "print(f\"Dataset: {orders.name}\")\n",
    "print(f\"Rows: {orders.row_count}\")\n",
    "print(f\"Columns: {orders.column_count}\")\n",
    "print(f\"Column names: {orders.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "orders.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "### Other Connection Examples\n",
    "\n",
    "```python\n",
    "# Parquet files\n",
    "data = connect(\"data/events.parquet\")\n",
    "\n",
    "# JSON files\n",
    "data = connect(\"data/users.json\")\n",
    "\n",
    "# Cloud storage\n",
    "data = connect(\"s3://bucket/data.parquet\")\n",
    "data = connect(\"gs://bucket/data.csv\")\n",
    "\n",
    "# Databases\n",
    "data = connect(\"postgres://user:pass@host/db\", table=\"orders\")\n",
    "data = connect(\"snowflake://account/db\", table=\"orders\", schema=\"public\")\n",
    "data = connect(\"bigquery://project/dataset\", table=\"orders\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": "## 3. Exploring Columns\n\nAccess columns using attribute or bracket notation to get statistics."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access a column\n",
    "customer_col = orders.customer_id\n",
    "\n",
    "# View column statistics\n",
    "print(f\"Column: {customer_col.name}\")\n",
    "print(f\"Total values: {customer_col.total_count}\")\n",
    "print(f\"Null count: {customer_col.null_count}\")\n",
    "print(f\"Null %: {customer_col.null_percent:.2f}%\")\n",
    "print(f\"Unique count: {customer_col.unique_count}\")\n",
    "print(f\"Unique %: {customer_col.unique_percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric column statistics\n",
    "amount_col = orders.total_amount\n",
    "\n",
    "print(f\"Column: {amount_col.name}\")\n",
    "print(f\"Min: {amount_col.min}\")\n",
    "print(f\"Max: {amount_col.max}\")\n",
    "print(f\"Mean: {amount_col.mean:.2f}\")\n",
    "print(f\"Median: {amount_col.median}\")\n",
    "print(f\"Stddev: {amount_col.stddev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View value distribution\n",
    "orders.status.get_value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Quality Scores\n",
    "\n",
    "Calculate data quality scores across standard dimensions:\n",
    "- **Completeness**: Are all required values present?\n",
    "- **Uniqueness**: Are values appropriately unique?\n",
    "- **Validity**: Do values conform to expected formats/ranges?\n",
    "- **Consistency**: Are values consistent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quality score\n",
    "result = orders.score()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"DATA QUALITY REPORT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nOverall Score: {result.overall:.1f} / 100\")\n",
    "print(f\"Grade: {result.grade}\")\n",
    "print(f\"\\nDimension Scores:\")\n",
    "print(f\"  Completeness: {result.completeness:.1f}\")\n",
    "print(f\"  Uniqueness:   {result.uniqueness:.1f}\")\n",
    "print(f\"  Validity:     {result.validity:.1f}\")\n",
    "print(f\"  Consistency:  {result.consistency:.1f}\")\n",
    "print(f\"\\nChecks: {result.passed_checks}/{result.total_checks} passed ({result.pass_rate:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": "## 5. YAML-Based Rules (NEW in v2.0)\n\nDefine data quality rules in YAML with a simple, intuitive syntax. This is easier than Soda's SodaCL!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "# Define rules directly in Python using YAML string\n# Note: Our sample data has intentional nulls and anomalies, so we use thresholds\nyaml_rules = \"\"\"\ndataset: orders\ndescription: Data quality rules for orders\n\nrules:\n  # Table-level rules\n  - row_count > 0\n  - row_count < 1000000\n  \n  # Column-level rules with simple syntax\n  - order_id is not null\n  - order_id is unique\n  - customer_id null_percent < 10\n  - total_amount >= 0\n  - total_amount < 10000\n  - status in ['pending', 'shipped', 'delivered', 'cancelled']\n  - quantity >= 1\n\"\"\"\n\n# Load and execute rules\nrules = load_rules_from_string(yaml_rules)\nprint(f\"Loaded {len(rules.checks)} rules\")\nprint(f\"Dataset: {rules.dataset}\")\nprint(f\"\\nRules:\")\nfor check in rules.checks:\n    print(f\"  - {check.expression}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": "# Execute rules against the dataset\nresult = execute_rules(rules, dataset=orders)\n\nprint(f\"\\n{'='*60}\")\nprint(f\"RULE EXECUTION RESULTS\")\nprint(f\"{'='*60}\")\nprint(f\"Total: {result.total_checks}\")\nprint(f\"Passed: {result.passed_count}\")\nprint(f\"Failed: {result.failed_count}\")\nprint(f\"Success Rate: {result.quality_score:.1f}%\")\nprint(f\"\\nDetails:\")\nfor check_result in result.results:\n    status = \"PASS\" if check_result.passed else \"FAIL\"\n    print(f\"  [{status}] {check_result.check.expression}\")\n    if not check_result.passed:\n        print(f\"         -> {check_result.message}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-generate YAML rules from data analysis\n",
    "generated_yaml = generate_rules(orders, dataset_name=\"orders\")\n",
    "print(\"Generated YAML Rules:\")\n",
    "print(generated_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": "### Save Rules to a File\n\n```python\n# Save generated rules\nwith open(\"duckguard.yaml\", \"w\") as f:\n    f.write(generated_yaml)\n\n# Later, load and execute\nrules = load_rules(\"duckguard.yaml\")\nresult = execute_rules(rules, orders)\n```"
  },
  {
   "cell_type": "code",
   "id": "s1vvpxmry3",
   "source": "# Load rules from a YAML file (we have a sample file in sample_data/)\nfile_rules = load_rules(\"sample_data/duckguard.yaml\")\nprint(f\"Loaded {len(file_rules.checks)} rules from file\")\nprint(f\"Dataset: {file_rules.dataset}\")\nprint(f\"Description: {file_rules.description}\")\n\n# Execute the file-based rules (note: dataset must be passed as keyword argument)\nfile_result = execute_rules(file_rules, dataset=orders)\nprint(f\"\\nResults: {file_result.passed_count}/{file_result.total_checks} passed\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "uy32pduzaa",
   "source": "# Working with RuleSet programmatically\n# RuleSet allows you to build rules in code instead of YAML\n\n# Create an empty RuleSet\ncustom_rules = RuleSet(name=\"custom_orders\", version=\"1.0\", description=\"Custom rules\")\n\n# Add simple checks using expressions (same syntax as YAML)\ncustom_rules.add_simple_check(\"row_count > 0\")\ncustom_rules.add_simple_check(\"order_id is not null\")\ncustom_rules.add_simple_check(\"quantity >= 1\")\ncustom_rules.add_simple_check(\"status in ['pending', 'shipped', 'delivered', 'cancelled']\")\n\nprint(f\"RuleSet: {custom_rules.name}\")\nprint(f\"Version: {custom_rules.version}\")\nprint(f\"Description: {custom_rules.description}\")\nprint(f\"Total checks: {len(custom_rules.checks)}\")\nprint(f\"\\nRules added:\")\nfor check in custom_rules.checks:\n    print(f\"  - {check.expression}\")\n\n# Execute our programmatic rules (note: dataset must be passed as keyword argument)\ncustom_result = execute_rules(custom_rules, dataset=orders)\nprint(f\"\\nResults: {custom_result.passed_count}/{custom_result.total_checks} passed\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": "## 6. Semantic Type Detection (NEW in v2.0)\n\nDuckGuard automatically detects semantic types like emails, phone numbers, UUIDs, credit cards, and PII."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect semantic types for a single column\n",
    "email_type = detect_type(orders, \"email\")\n",
    "print(f\"Column 'email' detected as: {email_type.value if email_type else 'unknown'}\")\n",
    "\n",
    "order_id_type = detect_type(orders, \"order_id\")\n",
    "print(f\"Column 'order_id' detected as: {order_id_type.value if order_id_type else 'unknown'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect types for entire dataset\n",
    "type_results = detect_types_for_dataset(orders)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SEMANTIC TYPE DETECTION\")\n",
    "print(f\"{'='*60}\")\n",
    "for col_name, sem_type in type_results.items():\n",
    "    type_name = sem_type.value if sem_type else \"generic\"\n",
    "    print(f\"  {col_name:20} -> {type_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": "# Use the SemanticAnalyzer for detailed analysis\nanalyzer = SemanticAnalyzer()\nanalysis = analyzer.analyze(orders)\n\nprint(f\"\\nAnalysis Summary:\")\nprint(f\"  Columns analyzed: {len(analysis.columns)}\")\nprint(f\"  PII columns detected: {len(analysis.pii_columns)}\")\nif analysis.pii_columns:\n    print(f\"  PII warning: Columns {analysis.pii_columns} may contain PII!\")\n\nprint(f\"\\nDetected Types:\")\nfor col_analysis in analysis.columns:\n    confidence = f\"({col_analysis.confidence:.0%})\" if col_analysis.confidence else \"\"\n    detected = col_analysis.semantic_type.value if col_analysis.semantic_type else \"unknown\"\n    print(f\"  {col_analysis.name}: {detected} {confidence}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": "### Supported Semantic Types\n\nDuckGuard detects 30+ semantic types including:\n\n| Category | Types |\n|----------|-------|\n| **Identifiers** | UUID, Email, Phone, URL, IP Address |\n| **Financial** | Credit Card, Currency, IBAN |\n| **Personal (PII)** | SSN, Name, Address, Date of Birth |\n| **Geographic** | Country, State, Zip Code, Latitude, Longitude |\n| **Technical** | JSON, Timestamp, Version, File Path |"
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 7. Data Contracts (NEW in v2.0)\n",
    "\n",
    "Define schema expectations and quality SLAs with automatic breaking change detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": "# Auto-generate a contract from your data\ncontract = generate_contract(orders, name=\"orders_contract\", owner=\"data-team\")\n\nprint(f\"Contract: {contract.name}\")\nprint(f\"Version: {contract.version}\")\nprint(f\"Owner: {contract.metadata.owner}\")\nprint(f\"\\nSchema ({len(contract.schema)} columns):\")\nfor field in contract.schema:\n    req_status = \"required\" if field.required else \"optional\"\n    print(f\"  {field.name}: {field.type.value if hasattr(field.type, 'value') else field.type} ({req_status})\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": "# View quality SLAs in the contract\nif contract.quality:\n    print(\"Quality SLAs:\")\n    if contract.quality.completeness is not None:\n        print(f\"  Completeness: >= {contract.quality.completeness}%\")\n    if contract.quality.row_count_min is not None:\n        print(f\"  Min row count: {contract.quality.row_count_min}\")\n    if contract.quality.row_count_max is not None:\n        print(f\"  Max row count: {contract.quality.row_count_max}\")\n    if contract.quality.freshness:\n        print(f\"  Freshness: {contract.quality.freshness}\")\n    \n    if contract.quality.uniqueness:\n        print(\"\\n  Uniqueness requirements:\")\n        for col, pct in contract.quality.uniqueness.items():\n            print(f\"    {col}: {pct}%\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate data against a contract\n",
    "validation = validate_contract(contract, orders)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CONTRACT VALIDATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Valid: {validation.is_valid}\")\n",
    "print(f\"Schema valid: {validation.schema_valid}\")\n",
    "print(f\"Quality valid: {validation.quality_valid}\")\n",
    "\n",
    "if validation.errors:\n",
    "    print(f\"\\nErrors:\")\n",
    "    for error in validation.errors:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "if validation.warnings:\n",
    "    print(f\"\\nWarnings:\")\n",
    "    for warning in validation.warnings:\n",
    "        print(f\"  - {warning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": "# Export contract to YAML (contract_to_yaml was imported at the top)\ncontract_yaml = contract_to_yaml(contract)\nprint(\"Contract as YAML:\")\nprint(contract_yaml)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "### Breaking Change Detection\n",
    "\n",
    "Compare contracts to detect breaking changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": "# Simulate a contract change: make a required column optional (breaking change!)\nfrom duckguard.contracts import DataContract, SchemaField, FieldType\n\n# Original contract (order_id is required)\nold_contract = generate_contract(orders, dataset_name=\"orders_v1\", as_yaml=False)\n\n# New contract (modify to make order_id optional - a breaking change!)\nnew_contract = generate_contract(orders, dataset_name=\"orders_v2\", as_yaml=False)\n# Find and modify order_id field\nfor field in new_contract.schema:\n    if field.name == \"order_id\":\n        field.required = False  # This is a breaking change!\n\n# Detect breaking changes\ndiff_result = diff_contracts(old_contract, new_contract)\n\nprint(f\"\\nContract Diff:\")\nprint(f\"  Has breaking changes: {diff_result.has_breaking_changes}\")\nprint(f\"  Has changes: {diff_result.has_changes}\")\n\nif diff_result.breaking_changes:\n    print(f\"\\nBreaking Changes:\")\n    for change in diff_result.breaking_changes:\n        print(f\"  - {change}\")\n\nif diff_result.non_breaking_changes:\n    print(f\"\\nNon-Breaking Changes:\")\n    for change in diff_result.non_breaking_changes:\n        print(f\"  - {change}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "## 8. Anomaly Detection (NEW in v2.0)\n",
    "\n",
    "Detect statistical anomalies in your data using Z-score, IQR, or percent change methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick anomaly detection on numeric columns\n",
    "report = detect_anomalies(orders, method=\"zscore\", threshold=3.0)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ANOMALY DETECTION REPORT\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Source: {report.source}\")\n",
    "print(f\"Anomalies found: {report.anomaly_count}\")\n",
    "print(f\"\\n{report.summary()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed anomaly detection with custom settings\n",
    "detector = AnomalyDetector(method=\"iqr\", threshold=1.5)\n",
    "report = detector.detect(\n",
    "    orders,\n",
    "    columns=[\"quantity\", \"unit_price\", \"total_amount\"],\n",
    "    include_null_check=True\n",
    ")\n",
    "\n",
    "print(f\"Checked {report.statistics.get('columns_checked', 0)} columns\")\n",
    "print(f\"Method: {report.statistics.get('method')}\")\n",
    "print(f\"Threshold: {report.statistics.get('threshold')}\")\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "for anomaly in report.anomalies:\n",
    "    status = \"ANOMALY\" if anomaly.is_anomaly else \"OK\"\n",
    "    print(f\"  [{status}] {anomaly.column}: {anomaly.message}\")\n",
    "    if anomaly.is_anomaly and anomaly.samples:\n",
    "        print(f\"          Samples: {anomaly.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect anomalies with historical baseline\n",
    "# Useful for monitoring metrics over time\n",
    "\n",
    "# Simulate historical baseline values\n",
    "historical_totals = [50.0, 55.0, 48.0, 52.0, 51.0, 49.0, 53.0, 50.0]\n",
    "\n",
    "detector = AnomalyDetector(method=\"percent_change\", threshold=0.2)  # 20% change threshold\n",
    "result = detector.detect_column(\n",
    "    orders, \n",
    "    \"total_amount\",\n",
    "    baseline_values=historical_totals\n",
    ")\n",
    "\n",
    "print(f\"Column: {result.column}\")\n",
    "print(f\"Is Anomaly: {result.is_anomaly}\")\n",
    "print(f\"Score: {result.score:.2f}\")\n",
    "print(f\"Threshold: {result.threshold}\")\n",
    "print(f\"Message: {result.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "### Available Anomaly Detection Methods\n",
    "\n",
    "| Method | Description | Best For |\n",
    "|--------|-------------|----------|\n",
    "| `zscore` | Standard deviations from mean | Normal distributions |\n",
    "| `iqr` | Interquartile range | Robust to outliers |\n",
    "| `percent_change` | % change from baseline | Monitoring metrics |\n",
    "| `modified_zscore` | Uses median & MAD | Non-normal distributions |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-35",
   "metadata": {},
   "source": "## 9. Python Assertions (Traditional Approach)\n\nYou can still use simple Python assertions - DuckGuard integrates with pytest!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic checks using properties\n",
    "assert orders.row_count > 0, \"Dataset should not be empty\"\n",
    "assert orders.customer_id.null_percent < 5, \"Customer ID should have < 5% nulls\"\n",
    "assert orders.total_amount.min >= 0, \"Amounts should be non-negative\"\n",
    "\n",
    "print(\"All basic assertions passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation methods with detailed results\n",
    "result = orders.order_id.is_not_null(threshold=1.0)\n",
    "print(f\"is_not_null: {result}\")\n",
    "print(f\"  Message: {result.message}\")\n",
    "\n",
    "result = orders.total_amount.between(0, 100000)\n",
    "print(f\"\\nbetween: {result}\")\n",
    "print(f\"  Message: {result.message}\")\n",
    "\n",
    "result = orders.status.isin(['pending', 'shipped', 'delivered', 'cancelled'])\n",
    "print(f\"\\nisin: {result}\")\n",
    "print(f\"  Message: {result.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "ut31o921v4s",
   "source": "# More validation methods\nprint(\"Additional validation methods:\")\nprint(\"-\" * 60)\n\n# is_unique - check if column values are unique\nresult = orders.order_id.is_unique(threshold=100.0)\nprint(f\"is_unique: {result}\")\nprint(f\"  Message: {result.message}\")\n\n# matches - regex pattern matching\nresult = orders.email.matches(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$')\nprint(f\"\\nmatches (email pattern): {result}\")\nprint(f\"  Message: {result.message}\")\n\n# has_no_duplicates - check for duplicate values\nresult = orders.order_id.has_no_duplicates()\nprint(f\"\\nhas_no_duplicates: {result}\")\nprint(f\"  Message: {result.message}\")\n\n# greater_than - value comparison\nresult = orders.quantity.greater_than(0)\nprint(f\"\\ngreater_than(0): {result}\")\nprint(f\"  Message: {result.message}\")\n\n# less_than - value comparison\nresult = orders.unit_price.less_than(1000)\nprint(f\"\\nless_than(1000): {result}\")\nprint(f\"  Message: {result.message}\")\n\n# value_lengths_between - string length validation\nresult = orders.order_id.value_lengths_between(7, 7)  # ORD-XXX format = 7 chars\nprint(f\"\\nvalue_lengths_between(7, 7): {result}\")\nprint(f\"  Message: {result.message}\")\n\n# get_distinct_values - view unique values\ndistinct_products = orders.product_name.get_distinct_values(limit=5)\nprint(f\"\\nget_distinct_values (products): {distinct_products}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-38",
   "metadata": {},
   "source": "## 10. Auto-Profiling\n\nLet DuckGuard analyze your data and suggest validation rules."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": "from duckguard.profiler import AutoProfiler\n\n# Profile the dataset\nprofiler = AutoProfiler(dataset_var_name=\"orders\")\nprofile_result = profiler.profile(orders)\n\nprint(f\"Profiled: {profile_result.source}\")\nprint(f\"Rows: {profile_result.row_count}\")\nprint(f\"Columns: {profile_result.column_count}\")\nprint(f\"\\nSuggested Rules ({len(profile_result.suggested_rules)}):\")\nprint(\"-\" * 60)\nfor rule in profile_result.suggested_rules[:10]:  # Show first 10\n    print(rule)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": "## 11. Using with pytest\n\nDuckGuard integrates seamlessly with pytest. Create a test file:\n\n```python\n# test_data_quality.py\nimport pytest\nfrom duckguard import connect, load_rules, execute_rules, validate_contract, load_contract\n\n@pytest.fixture\ndef orders():\n    return connect(\"data/orders.csv\")\n\n# Test with YAML rules\ndef test_yaml_rules(orders):\n    rules = load_rules(\"duckguard.yaml\")\n    result = execute_rules(rules, orders)\n    assert result.failed == 0, f\"Failed checks: {result.failed}\"\n\n# Test with data contract\ndef test_contract(orders):\n    contract = load_contract(\"contract.yaml\")\n    result = validate_contract(contract, orders)\n    assert result.is_valid, f\"Contract violations: {result.errors}\"\n\n# Traditional assertion tests\ndef test_orders_not_empty(orders):\n    assert orders.row_count > 0\n\ndef test_order_ids_valid(orders):\n    assert orders.order_id.null_percent == 0\n    assert orders.order_id.has_no_duplicates()\n\ndef test_quality_score(orders):\n    score = orders.score()\n    assert score.overall >= 80, f\"Quality score too low: {score.overall}\"\n```\n\nRun with: `pytest test_data_quality.py -v`"
  },
  {
   "cell_type": "markdown",
   "id": "cell-41",
   "metadata": {},
   "source": "## 12. CLI Commands (NEW in v2.0)\n\nDuckGuard provides powerful CLI commands with beautiful Rich output:\n\n```bash\n# Quick check with auto-generated rules\nduckguard check data/orders.csv\n\n# Check with YAML rules file\nduckguard check data/orders.csv --config duckguard.yaml\n\n# Discover data and generate rules\nduckguard discover data/orders.csv\nduckguard discover data/orders.csv --output duckguard.yaml\n\n# Generate data contract\nduckguard contract generate data/orders.csv\nduckguard contract generate data/orders.csv --output contract.yaml --owner \"data-team\"\n\n# Validate against contract\nduckguard contract validate data/orders.csv --contract contract.yaml\n\n# Compare contracts for breaking changes\nduckguard contract diff old_contract.yaml new_contract.yaml\n\n# Detect anomalies\nduckguard anomaly data/orders.csv\nduckguard anomaly data/orders.csv --method iqr --threshold 1.5\n\n# Show version and info\nduckguard info\n```"
  },
  {
   "cell_type": "markdown",
   "id": "cell-42",
   "metadata": {},
   "source": "## 13. Quick Reference\n\n### YAML Rule Syntax\n\n```yaml\ndataset: my_data\nrules:\n  # Table-level\n  - row_count > 0\n  - row_count < 1000000\n  \n  # Column nulls\n  - column_name is not null\n  - column_name null_percent < 5\n  \n  # Uniqueness\n  - column_name is unique\n  - column_name unique_percent > 95\n  \n  # Ranges\n  - column_name >= 0\n  - column_name between 0 and 100\n  \n  # Sets\n  - column_name in ['a', 'b', 'c']\n  \n  # Patterns\n  - column_name matches '^[A-Z]{3}$'\n```\n\n### Semantic Types Detected\n\n- `email`, `phone`, `url`, `ip_address`\n- `uuid`, `credit_card`, `iban`\n- `ssn`, `date_of_birth` (PII)\n- `country`, `state`, `zip_code`\n- `latitude`, `longitude`\n- `timestamp`, `currency`, `percentage`\n\n### Contract Validation\n\n- Schema: column names, types, nullability\n- Quality: completeness, null %, custom rules\n- Breaking changes: removed columns, type changes, nullability\n\n### Anomaly Detection Methods\n\n| Method | Threshold | Use Case |\n|--------|-----------|----------|\n| `zscore` | 3.0 (std devs) | Normal data |\n| `iqr` | 1.5 (IQR multiplier) | Outlier-robust |\n| `percent_change` | 0.2 (20%) | Time-series monitoring |\n| `modified_zscore` | 3.5 | Non-normal distributions |"
  },
  {
   "cell_type": "markdown",
   "id": "cell-43",
   "metadata": {},
   "source": "## 14. Next Steps\n\n- **Documentation**: https://duckguard.dev\n- **GitHub**: https://github.com/duckguard/duckguard\n- **Issues**: https://github.com/duckguard/duckguard/issues\n\n### What to explore next:\n1. Generate a `duckguard.yaml` file for your data with `duckguard discover`\n2. Create a data contract with `duckguard contract generate`\n3. Set up anomaly monitoring with `duckguard anomaly`\n4. Add rules to your CI/CD pipeline with pytest\n5. Detect PII with semantic type detection"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}